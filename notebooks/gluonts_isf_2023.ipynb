{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with Deep Learning models using GluonTS\n",
    "\n",
    "Case study via the [M5 forecasting competition dataset](https://www.kaggle.com/competitions/m5-forecasting-accuracy).\n",
    "\n",
    "M-competitions named after Spyros Makridakis, currently in their [6th edition](https://mofc.unic.ac.cy/the-m6-competition/).\n",
    "\n",
    "M5 data provided by Walmart.\n",
    "\n",
    "We assume the data set is downloaded locally (we can't provide it for Kaggle licensing)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M5 dataset\n",
    "\n",
    "* 42,840 hierarchical time series, 3049 products from 3 categories, 7 departments\n",
    "\n",
    "* 3 US states: California (CA), Texas (TX), and Wisconsin (WI), 10 stores\n",
    "\n",
    "* “Hierarchical” levels: item level, department level, product category level, and state level.\n",
    "\n",
    "* Daily sales: Jan 2011 to June 2016. \n",
    "\n",
    "* included co-variates: prices, promotions, and holidays. \n",
    "\n",
    "* no missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We use mainly standard pandas to load and manipulate data, for GluonTS models to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from gluonts.dataset.pandas import PandasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = pd.read_csv(\n",
    "    Path(\"m5-forecasting-accuracy\") / \"calendar.csv\",\n",
    ")\n",
    "\n",
    "weekly_prices = pd.read_csv(\n",
    "    Path(\"m5-forecasting-accuracy\") / \"sell_prices.csv\",\n",
    ")\n",
    "\n",
    "sales_and_features = pd.read_csv(\n",
    "    Path(\"m5-forecasting-accuracy\") / \"sales_train_validation.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sales_and_features[\"item_id\"].unique()) == 3049\n",
    "assert len(sales_and_features[\"store_id\"].unique()) == 10\n",
    "assert len(sales_and_features) == 30490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_and_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a subset of this to make things a bit faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_and_features = sales_and_features[sales_and_features.dept_id == \"FOODS_3\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split the data into static (categorical features) vs dynamic (sales data). We keep the 'id' column in both, to be able to join the two. We also keep 'item_id' and 'store_id' in the sales data, to be able to join with prices later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [\"id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
    "sales_columns = [\"id\", \"item_id\", \"store_id\"] + [f\"d_{k}\" for k in range(1, 1914)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into static (categorical features) vs dynamic (sales data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sales_and_features[features_columns].set_index(\"id\").astype(\"category\")\n",
    "sales = sales_and_features[sales_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(features) == 30490\n",
    "assert len(features.columns) == 4\n",
    "assert len(sales) == 30490\n",
    "assert len(sales.columns) == 1916"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn sales data into long format, to join with prices more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_long = sales.melt(id_vars=[\"id\", \"item_id\", \"store_id\"], var_name=\"d\", value_name=\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join sales data with prices, first we add the `\"wm_yr_wk\"` column from `cal`. We also add the `\"date\"` column to build the time index. Then we join with `weekly_prices` on `\"store_id\"`, `\"item_id\"`, `\"wm_yr_wk\"`, to get the `\"sell_price\"` column in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sales_long.merge(\n",
    "    cal[[\"d\", \"wm_yr_wk\", \"date\"]], on=\"d\", how=\"left\", suffixes=(None, \"_right\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices = temp.merge(weekly_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\", suffixes=(None, \"_right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices.index = pd.to_datetime(sales_with_prices[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sales_with_prices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows have missing price, which means the item was not for sale. Let's replace price there with some constant, and add a column indicating whether the product was for sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices[\"for_sale\"] = sales_with_prices[\"sell_price\"].notna()\n",
    "sales_with_prices[\"sell_price\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we want to keep our target and feature columns as float32, to be compatible with the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices[\"sales\"] = sales_with_prices[\"sales\"].astype(np.float32)\n",
    "sales_with_prices[\"sell_price\"] = sales_with_prices[\"sell_price\"].astype(np.float32)\n",
    "sales_with_prices[\"for_sale\"] = sales_with_prices[\"for_sale\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to construct our dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PandasDataset.from_long_dataframe(\n",
    "    sales_with_prices,\n",
    "    item_id=\"id\",\n",
    "    target=\"sales\",\n",
    "    feat_dynamic_real=[\"sell_price\", \"for_sale\"],\n",
    "    static_features=features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset:\n",
    "    pprint(entry)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE: fake data just to try things out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = [\n",
    "    {\n",
    "        \"start\": pd.Period(\"2022-03-04\", freq=\"D\"),\n",
    "        \"target\": np.random.normal(size=1000),\n",
    "        \"feat_dynamic_real\": np.random.normal(size=(2, 1000)).astype(np.float32),\n",
    "        \"feat_static_cat\": np.array([0, 1, 2]),\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A transformer model\n",
    "\n",
    "We will train a transformer-based architecture (temporal fusion transformer, TFT?) on the above data.\n",
    "\n",
    "Models in GluonTS are exposed as \"estimator\" objects: these take care of some data pre-processing (like replacing missing values in the data, and adding missing value indicator features, adding other calendar-related features, possibly other things depending on the model). An estimator is then trained with a training and validation datasets, and produces a \"predictor\" that contains the trained model to be used for prediction.\n",
    "\n",
    "We will use a PyTorch-based estimator, which wraps the [Temporal Fusion Transformer model](https://arxiv.org/abs/1912.09363). This estimator relies on PyTorch Lightning for training, which means we can use all tooling available for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch.model.tft import TemporalFusionTransformerEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TemporalFusionTransformerEstimator(\n",
    "    freq=\"1D\",\n",
    "    prediction_length=7,\n",
    "    context_length=180,\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    "    static_cardinalities=[1, 2, 3], #dataset.static_cardinalities.tolist(),\n",
    "    dynamic_dims=[2],\n",
    "    batch_size=32,\n",
    "    trainer_kwargs={\n",
    "        \"max_epochs\": 20,\n",
    "        \"logger\": TensorBoardLogger(\"tb_logs\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn the dataset into a list, for faster iteration (good for training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, _ = split(validation_dataset, offset=-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(training_data=training_dataset, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting, evaluating, comparing\n",
    "\n",
    "We will plot forecasts, evaluate accuracy and identify worst-cases, compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Tuning the model hyperparameters (a.g. architectural choices, number of layers, hidden layers sizes, etc.) is often important to get the best results. GluonTS does not provide model tuning features out of the box, but interfaces easily for dedicated toolboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import MASE\n",
    "from gluonts.model.evaluation import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, validation_gen = split(dataset, offset=-7)\n",
    "validation_data = validation_gen.generate_instances(prediction_length=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evaluate_model(predictor, test_data=validation_data, metrics=[MASE()], seasonality=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tft_tuning_objective(trial):\n",
    "    # get suggested hyperparameters values\n",
    "    context_length = trial.suggest_int(\"context_length\", 30, 180)\n",
    "    variable_dim = trial.suggest_int(\"variable_dim\", 10, 50)\n",
    "\n",
    "    # set up model\n",
    "    estimator = TemporalFusionTransformerEstimator(\n",
    "        freq=\"1D\",\n",
    "        prediction_length=7,\n",
    "        context_length=context_length,\n",
    "        quantiles=[0.1, 0.5, 0.9],\n",
    "        static_cardinalities=[1, 2, 3], #dataset.static_cardinalities.tolist(),\n",
    "        dynamic_dims=[2],\n",
    "        variable_dim=variable_dim,\n",
    "        batch_size=32,\n",
    "        trainer_kwargs={\n",
    "            \"max_epochs\": 1,  # TODO set larger\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    predictor = estimator.train(training_dataset)\n",
    "\n",
    "    # evaluate model\n",
    "    df = evaluate_model(predictor, test_data=validation_data, metrics=[MASE()], seasonality=1)\n",
    "    return df[\"MASE[0.5]\"].iloc[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = study.optimize(tft_tuning_objective, n_trials=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for experiments\n",
    "\n",
    "Besides the specific M5 use-case above, it is important to validate the performance of a model class against multiple datasets. This is especially true when working on novel architectures, or adapting architectures from other domains (NLP, computer vision) to time series."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluonts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ece9bdd984f8cd41222b51b2510f420829ccf1d6b5fba4524095ddc78fa60611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
