{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with Deep Learning models using GluonTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub repo: https://github.com/awslabs/gluon-ts\n",
    "\n",
    "Documentation: https://ts.gluon.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"gluonts[torch]~=0.13.2\" matplotlib orjson tensorboard optuna datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GluonTS is a Python library for deep learning based forecasting models. It provides:\n",
    "\n",
    "1. Model implementations (initially in MXNet, now moving to PyTorch)\n",
    "    \n",
    "    - DeepAR (RNN, sampling based)\n",
    "    \n",
    "    - MQ-CNN (CNN encoder + MLP decoder, quantile regression based)\n",
    "    \n",
    "    - WaveNet (data quantization + dilated convolutions, sampling based)\n",
    "    \n",
    "    - Transformer-based architectures (vanilla encoder/decoder transformer, TFT, PatchTST)\n",
    "\n",
    "\n",
    "1. Tools to construct data pipelines for the models\n",
    "    \n",
    "    - Missing value imputation and masking\n",
    "\n",
    "    - Adding calendar features\n",
    "\n",
    "    - Sampling and batching training instances\n",
    "\n",
    "    - Different forecasts types (e.g. samples vs quantiles)\n",
    "\n",
    "\n",
    "1. Evaluation utils\n",
    "    \n",
    "    - Splitting data for training/validation/test\n",
    "    \n",
    "    - Evaluating common metrics\n",
    "\n",
    "\n",
    "1. Dataset for experiments\n",
    "\n",
    "\n",
    "1. Model \"infrastructure\"\n",
    "    \n",
    "    - Serialization/deserialization of full model pipeline\n",
    "    \n",
    "    - Docker container to train/deploy model in the cloud (e.g. Amazon SageMaker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/lostella/isf-deep-learning-workshop/blob/main/notebooks/figures/flow.png?raw=true\" alt=\"flow\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M5 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case study via the [M5 forecasting competition dataset](https://www.kaggle.com/competitions/m5-forecasting-accuracy). M-competitions named after Spyros Makridakis, currently in their [6th edition](https://mofc.unic.ac.cy/the-m6-competition/). M5 data provided by Walmart. We assume the data set is downloaded locally (we can't provide it for Kaggle licensing)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* 42,840 hierarchical time series, 3049 products from 3 categories, 7 departments\n",
    "\n",
    "* 3 US states: California (CA), Texas (TX), and Wisconsin (WI), 10 stores\n",
    "\n",
    "* “Hierarchical” levels: item level, department level, product category level, and state level.\n",
    "\n",
    "* Daily sales: Jan 2011 to June 2016. \n",
    "\n",
    "* included co-variates: prices, promotions, and holidays. \n",
    "\n",
    "* no missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We use mainly standard pandas to load and manipulate data, for GluonTS models to use.\n",
    "\n",
    "Goal: bring data into a format that GluonTS models can consume, for training or for prediction. That is, a collection of `dict` with\n",
    "* `start` attribute for timestamp (`pd.Period`)\n",
    "* `target` attribute for the sequence we want to model (`np.ndarray`)\n",
    "* other attributes for features (in this example, `feat_dynamic_real` and `feat_static_cat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_files_path = Path(\"m5-forecasting-accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = pd.read_csv(m5_files_path / \"calendar.csv\")\n",
    "weekly_prices = pd.read_csv(m5_files_path / \"sell_prices.csv\")\n",
    "sales_and_features = pd.read_csv(m5_files_path / \"sales_train_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sales_and_features[\"item_id\"].unique()) == 3049\n",
    "assert len(sales_and_features[\"store_id\"].unique()) == 10\n",
    "assert len(sales_and_features) == 30490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_and_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a subset of this to make things a bit faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_and_features = sales_and_features[sales_and_features.dept_id == \"FOODS_3\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split the data into static (categorical features) vs dynamic (sales data). We keep the 'id' column in both, to be able to join the two. We also keep 'item_id' and 'store_id' in the sales data, to be able to join with prices later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = [\"id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
    "sales_columns = [\"id\", \"item_id\", \"store_id\"] + [f\"d_{k}\" for k in range(1, 1914)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into static (categorical features) vs dynamic (sales data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sales_and_features[features_columns].set_index(\"id\").astype(\"category\")\n",
    "sales = sales_and_features[sales_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn sales data into long format, to join with prices more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_long = sales.melt(id_vars=[\"id\", \"item_id\", \"store_id\"], var_name=\"d\", value_name=\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join sales data with prices, first we add the `\"wm_yr_wk\"` column from `cal`. We also add the `\"date\"` column to build the time index. Then we join with `weekly_prices` on `\"store_id\"`, `\"item_id\"`, `\"wm_yr_wk\"`, to get the `\"sell_price\"` column in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sales_long.merge(\n",
    "    cal[[\"d\", \"wm_yr_wk\", \"date\"]], on=\"d\", how=\"left\", suffixes=(None, \"_right\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices = temp.merge(weekly_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\", suffixes=(None, \"_right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices.index = pd.to_datetime(sales_with_prices[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sales_with_prices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows have missing price, which means the item was not for sale. Let's replace price there with some constant, and add a column indicating whether the product was for sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices[\"for_sale\"] = sales_with_prices[\"sell_price\"].notna()\n",
    "sales_with_prices[\"sell_price\"].fillna(0.0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we want to keep our target and feature columns as float32, to be compatible with the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices[\"sales\"] = sales_with_prices[\"sales\"].astype(np.float32)\n",
    "sales_with_prices[\"sell_price\"] = sales_with_prices[\"sell_price\"].astype(np.float32)\n",
    "sales_with_prices[\"for_sale\"] = sales_with_prices[\"for_sale\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_with_prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to construct our dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PandasDataset.from_long_dataframe(\n",
    "    sales_with_prices,\n",
    "    item_id=\"id\",\n",
    "    target=\"sales\",\n",
    "    feat_dynamic_real=[\"sell_price\", \"for_sale\"],\n",
    "    static_features=features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset:\n",
    "    pprint(entry)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store some metadata and turn the dataset into a list: this will be faster to iterate compared to `PandasDataset` (good for model training and evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat_dynamic_real = dataset.num_feat_dynamic_real\n",
    "static_cardinalities = dataset.static_cardinalities.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A transformer model\n",
    "\n",
    "We will train a transformer-based architecture ([Temporal Fusion Transformer model](https://arxiv.org/abs/1912.09363), TFT) on the above data.\n",
    "\n",
    "Models in GluonTS are exposed as \"estimator\" objects. These define the full model pipeline:\n",
    "\n",
    "* data pre-processing (replacing missing values in the data, adding other calendar-related features, ...)\n",
    "\n",
    "* how data is sampled for training\n",
    "\n",
    "* the specific deep learning model to use\n",
    "\n",
    "* any post-processing to the model output to turn it into a forecast\n",
    "\n",
    "An estimator is trained with a training and validation datasets, and produces a \"predictor\" that contains the trained model to be used for prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/lostella/isf-deep-learning-workshop/blob/main/notebooks/figures/flow.png?raw=true\" alt=\"flow\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.torch.model.tft import TemporalFusionTransformerEstimator\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TemporalFusionTransformerEstimator(\n",
    "    freq=\"1D\",\n",
    "    prediction_length=7,\n",
    "    context_length=180,\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    "    static_cardinalities=static_cardinalities,\n",
    "    dynamic_dims=[num_feat_dynamic_real],\n",
    "    batch_size=32,\n",
    "    trainer_kwargs={\n",
    "        \"max_epochs\": 20,\n",
    "        \"logger\": TensorBoardLogger(\"tb_logs\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.split import split\n",
    "\n",
    "training_dataset, test_gen = split(dataset, offset=-21)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Link Name](https://github.com/lostella/isf-deep-learning-workshop/blob/main/notebooks/figures/split1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_gen.generate_instances(prediction_length=7, windows=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Link Name](https://github.com/lostella/isf-deep-learning-workshop/blob/main/notebooks/figures/split2.png?raw=true)\n",
    "![Link Name](https://github.com/lostella/isf-deep-learning-workshop/blob/main/notebooks/figures/split3.png?raw=true)\n",
    "![Link Name](https://github.com/lostella/isf-deep-learning-workshop/blob/main/notebooks/figures/split4.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again to keep runtime low, let's only generate a single backtest window per each series in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_gen.generate_instances(prediction_length=7, windows=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"tft_predictor\")\n",
    "model_path.mkdir(exist_ok=True)\n",
    "\n",
    "predictor.serialize(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model import Predictor\n",
    "predictor = Predictor.deserialize(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's inside a model\n",
    "\n",
    "* a [`torch.nn.module` class](https://github.com/awslabs/gluonts/blob/3ccb6d377a5bf9b27de74a47cdab295f4d61f7a7/src/gluonts/torch/model/tft/module.py#L35), implementing the network iteself\n",
    "\n",
    "* a [`pytorch_lightning.LightningModule`](https://github.com/awslabs/gluonts/blob/3ccb6d377a5bf9b27de74a47cdab295f4d61f7a7/src/gluonts/torch/model/tft/lightning_module.py#L24) defines how the model is to be trained\n",
    "\n",
    "* a [data preprocessing pipeline](https://github.com/awslabs/gluonts/blob/3ccb6d377a5bf9b27de74a47cdab295f4d61f7a7/src/gluonts/torch/model/tft/estimator.py#L211-L286) is used to construct batches to feed the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting, evaluating, comparing\n",
    "\n",
    "We will plot forecasts, evaluate accuracy and identify worst-cases, compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_tft = list(predictor.predict(test_data.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_tft[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "for (input, target), forecast in islice(zip(test_data, forecasts_tft), 3):\n",
    "    plt.figure()\n",
    "    plt.plot(to_pandas(input)[-100:].to_timestamp())\n",
    "    plt.plot(to_pandas(target).to_timestamp())\n",
    "    forecast.plot(intervals=(0.3, 0.8), color=\"green\")\n",
    "    # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating and comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import RMSE, MASE, MeanWeightedSumQuantileLoss\n",
    "from gluonts.model.evaluation import evaluate_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_forecasts(\n",
    "    forecasts_tft,\n",
    "    test_data=test_data,\n",
    "    metrics=[RMSE(), MASE(), MeanWeightedSumQuantileLoss([0.1, 0.5, 0.9])],\n",
    "    seasonality=1,\n",
    "    axis=1  # aggregate over time axis\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omitting the `axis` we get metrics aggregate over all axes (time + dataset dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_tft = evaluate_forecasts(\n",
    "    forecasts_tft,\n",
    "    test_data=test_data,\n",
    "    metrics=[RMSE(), MASE(), MeanWeightedSumQuantileLoss([0.1, 0.5, 0.9])],\n",
    "    seasonality=1,\n",
    ")\n",
    "metrics_tft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for a baseline model (naive) and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model.seasonal_naive import SeasonalNaivePredictor\n",
    "\n",
    "forecasts_naive = list(tqdm(\n",
    "    SeasonalNaivePredictor(freq=\"D\", prediction_length=7, season_length=1).predict(test_data.input)\n",
    "))\n",
    "\n",
    "metrics_naive = evaluate_forecasts(\n",
    "    forecasts_naive,\n",
    "    test_data=test_data,\n",
    "    metrics=[RMSE(), MASE(), MeanWeightedSumQuantileLoss([0.1, 0.5, 0.9])],\n",
    "    seasonality=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat({\"TFT\": metrics_tft, \"Naive\": metrics_naive})\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Tuning the model hyperparameters (a.g. architectural choices, number of layers, hidden layers sizes, etc.) is often important to get the best results.\n",
    "\n",
    "GluonTS **does not** provide model tuning features out of the box, but interfaces easily with dedicated packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tft_tuning_objective(trial):\n",
    "    # get suggested hyperparameters values\n",
    "    context_length = trial.suggest_int(\"context_length\", 30, 180)\n",
    "    variable_dim = trial.suggest_int(\"variable_dim\", 10, 50)\n",
    "\n",
    "    # set up model\n",
    "    estimator = TemporalFusionTransformerEstimator(\n",
    "        freq=\"1D\",\n",
    "        prediction_length=7,\n",
    "        context_length=context_length,\n",
    "        quantiles=[0.1, 0.5, 0.9],\n",
    "        static_cardinalities=static_cardinalities,\n",
    "        dynamic_dims=[num_feat_dynamic_real],\n",
    "        variable_dim=variable_dim,\n",
    "        batch_size=32,\n",
    "        trainer_kwargs={\n",
    "            \"max_epochs\": 5,  # TODO set larger\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    predictor = estimator.train(training_dataset)\n",
    "\n",
    "    # predict\n",
    "    forecasts = list(predictor.predict(test_data.input))\n",
    "\n",
    "    # evaluate model\n",
    "    df = evaluate_forecasts(forecasts, test_data=test_data, metrics=[MASE()], seasonality=1)\n",
    "    return df[\"MASE\"].iloc[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = study.optimize(tft_tuning_objective, n_trials=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other datasets for experiments\n",
    "\n",
    "It is important to validate the performance of a model class against multiple datasets. This is especially true when working on novel architectures, or adapting architectures from other domains (NLP, computer vision) to time series.\n",
    "\n",
    "Examples of available public datasets include the [Monash Time Series Repository](https://forecastingdata.org/), and there are several other available.\n",
    "\n",
    "Many of these are accessible directly through GluonTS or HuggingFace:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GluonTS dataset repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository import get_dataset, dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = get_dataset(\"solar-energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in solar.train:\n",
    "    print(entry)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in solar.test:\n",
    "    print(entry)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "traffic = load_dataset(\"monash_tsf\", \"traffic_hourly\")\n",
    "dataset_training = ListDataset(traffic[\"train\"], freq=\"H\")\n",
    "dataset_testing = ListDataset(traffic[\"test\"], freq=\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset_training:\n",
    "    print(entry)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset_testing:\n",
    "    print(entry)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluonts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ece9bdd984f8cd41222b51b2510f420829ccf1d6b5fba4524095ddc78fa60611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
